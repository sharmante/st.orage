{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "ResNet : 스킵커넥션을 이용해 기울기 소실 문제를 어느정도 해소\n",
        "-> 가장 깊은 ResNet 모델 : 합성곱을 100층까지 쌓을 수 있을 정도로 깊은 신경망\n",
        "\n",
        "F(x)값을 0으로 만든다는 뚜렷한 목표가 있는 모델 -> 학습이 쉬워짐"
      ],
      "metadata": {
        "id": "02CqKBie-BbW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet 기본 블록"
      ],
      "metadata": {
        "id": "9jaHxFEmBly-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ZCCmzu729PT0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, kernel_size=3):\n",
        "    super(BasicBlock, self).__init__()\n",
        "\n",
        "    self.c1 = nn.Conv2d(in_channels, out_channels,\n",
        "                        kernel_size=kernel_size, padding=1)\n",
        "    self.c2 = nn.Conv2d(out_channels, out_channels,\n",
        "                        kernel_size=kernel_size, padding=1)\n",
        "    self.downsample = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    self.bn1 = nn.BatchNorm2d(num_features=out_channels)\n",
        "    self.bn2 = nn.BatchNorm2d(num_features=out_channels)\n",
        "\n",
        "    self.relu = nn.ReLU()\n",
        "  #모델의 순전파 정의\n",
        "  def forward(self, x):\n",
        "    x_ = x\n",
        "\n",
        "    x = self.c1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.c2(x)\n",
        "    x = self.bn2(x)\n",
        "\n",
        "    x_ = self.downsample(x_)\n",
        "\n",
        "    x += x_\n",
        "    x = self.relu(x)\n",
        "\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet 모델 정의"
      ],
      "metadata": {
        "id": "PWh1aeuIC8Jg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "  def __init__(self, num_classes=10):\n",
        "    super(ResNet, self).__init__()\n",
        "\n",
        "    self.b1 = BasicBlock(in_channels=3, out_channels=64)\n",
        "    self.b2 = BasicBlock(in_channels=64, out_channels=128)\n",
        "    self.b3 = BasicBlock(in_channels=128, out_channels=256)\n",
        "\n",
        "    self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    self.fc1 = nn.Linear(in_features = 4096, out_features = 2048)\n",
        "    self.fc2 = nn.Linear(in_features = 2048, out_features = 512)\n",
        "    self.fc3 = nn.Linear(in_features = 512, out_features = num_classes)\n",
        "\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  #모델 순전파 정의\n",
        "  def forward(self, x):\n",
        "    x = self.b1(x)\n",
        "    x = self.pool(x)\n",
        "    x = self.b2(x)\n",
        "    x = self.pool(x)\n",
        "    x = self.b3(x)\n",
        "    x = self.pool(x)\n",
        "\n",
        "    x = torch.flatten(x,start_dim=1)\n",
        "\n",
        "    x = self.fc1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.fc3(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "64ZdgssUD4v2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 전처리 과정"
      ],
      "metadata": {
        "id": "f6J306dXDjtc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "from torchvision.datasets.cifar import CIFAR10\n",
        "from torchvision.transforms import Compose, ToTensor\n",
        "from torchvision.transforms import RandomHorizontalFlip, RandomCrop, Normalize\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.optim.adam import Adam\n",
        "\n",
        "transforms = Compose([\n",
        "    RandomCrop((32,32), padding = 4),\n",
        "    RandomHorizontalFlip(p=0.5),\n",
        "    ToTensor(),\n",
        "    Normalize(mean=(0.4914,0.4822,0.4465), std=(0.247,0.243,0.261))\n",
        "])"
      ],
      "metadata": {
        "id": "Hm1j8NSJJt-O"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = CIFAR10(root= \"./\",train= True, download=True, transform = transforms)\n",
        "test_data = CIFAR10(root=\"./\", train = False, download = True, transform = transforms)\n",
        "\n",
        "train_loader = DataLoader(training_data, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ho7uqVh6J-X8",
        "outputId": "d166594e-52e0-4443-b5c0-51579f8f5a16"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = ResNet(num_classes= 10)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnWUQj97KAve",
        "outputId": "8150feda-1a36-4170-896c-c3bc06c182dd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (b1): BasicBlock(\n",
              "    (c1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (c2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (downsample): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (b2): BasicBlock(\n",
              "    (c1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (c2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (downsample): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (b3): BasicBlock(\n",
              "    (c1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (c2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (downsample): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "  (fc1): Linear(in_features=4096, out_features=2048, bias=True)\n",
              "  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "  (fc3): Linear(in_features=512, out_features=10, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 학습"
      ],
      "metadata": {
        "id": "aSmVM0C7KqhM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1e-4\n",
        "optim = Adam(model.parameters(), lr = lr)\n",
        "\n",
        "for epoch in range(30):\n",
        "  iterator = tqdm.tqdm(train_loader)\n",
        "  for data, label in iterator:\n",
        "    optim.zero_grad()\n",
        "\n",
        "    preds = model(data.to(device))\n",
        "\n",
        "    loss = nn.CrossEntropyLoss()(preds, label.to(device))\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "\n",
        "    iterator.set_description(f\"epoch:{epoch+1} loss:{loss.item()}\")\n",
        "\n",
        "torch.save(model.state_dict(), \"ResNet.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkW3wr7fKYtA",
        "outputId": "1a5c6761-d7de-4e16-f2eb-5171a7dfe1a7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch:1 loss:0.10219169408082962: 100%|██████████| 1563/1563 [00:45<00:00, 34.05it/s]\n",
            "epoch:2 loss:0.006855418905615807: 100%|██████████| 1563/1563 [00:45<00:00, 34.44it/s]\n",
            "epoch:3 loss:0.2197248488664627: 100%|██████████| 1563/1563 [00:45<00:00, 34.36it/s]\n",
            "epoch:4 loss:0.008678584359586239: 100%|██████████| 1563/1563 [00:45<00:00, 34.45it/s]\n",
            "epoch:5 loss:0.010266783647239208: 100%|██████████| 1563/1563 [00:45<00:00, 34.49it/s]\n",
            "epoch:6 loss:0.03470255807042122: 100%|██████████| 1563/1563 [00:46<00:00, 33.89it/s]\n",
            "epoch:7 loss:0.14866903424263: 100%|██████████| 1563/1563 [00:45<00:00, 34.39it/s]\n",
            "epoch:8 loss:0.28750473260879517: 100%|██████████| 1563/1563 [00:45<00:00, 34.33it/s]\n",
            "epoch:9 loss:0.01875024288892746: 100%|██████████| 1563/1563 [00:45<00:00, 34.58it/s]\n",
            "epoch:10 loss:0.009039051830768585: 100%|██████████| 1563/1563 [00:45<00:00, 34.26it/s]\n",
            "epoch:11 loss:0.16495178639888763: 100%|██████████| 1563/1563 [00:46<00:00, 33.68it/s]\n",
            "epoch:12 loss:0.00013517876504920423: 100%|██████████| 1563/1563 [00:45<00:00, 34.22it/s]\n",
            "epoch:13 loss:0.10839719325304031: 100%|██████████| 1563/1563 [00:45<00:00, 34.67it/s]\n",
            "epoch:14 loss:0.020072314888238907: 100%|██████████| 1563/1563 [00:45<00:00, 34.31it/s]\n",
            "epoch:15 loss:0.014518601819872856: 100%|██████████| 1563/1563 [00:45<00:00, 34.15it/s]\n",
            "epoch:16 loss:0.007540303748100996: 100%|██████████| 1563/1563 [00:46<00:00, 33.66it/s]\n",
            "epoch:17 loss:0.032162103801965714: 100%|██████████| 1563/1563 [00:45<00:00, 34.56it/s]\n",
            "epoch:18 loss:0.057514190673828125: 100%|██████████| 1563/1563 [00:45<00:00, 34.38it/s]\n",
            "epoch:19 loss:0.027708033099770546: 100%|██████████| 1563/1563 [00:45<00:00, 34.19it/s]\n",
            "epoch:20 loss:0.20633678138256073: 100%|██████████| 1563/1563 [00:45<00:00, 34.42it/s]\n",
            "epoch:21 loss:0.41265425086021423: 100%|██████████| 1563/1563 [00:45<00:00, 34.13it/s]\n",
            "epoch:22 loss:0.03145136684179306: 100%|██████████| 1563/1563 [00:45<00:00, 34.51it/s]\n",
            "epoch:23 loss:0.010759556666016579: 100%|██████████| 1563/1563 [00:45<00:00, 34.17it/s]\n",
            "epoch:24 loss:0.0684676542878151: 100%|██████████| 1563/1563 [00:45<00:00, 34.31it/s]\n",
            "epoch:25 loss:0.003038256661966443: 100%|██████████| 1563/1563 [00:45<00:00, 34.69it/s]\n",
            "epoch:26 loss:0.005197327118366957: 100%|██████████| 1563/1563 [00:46<00:00, 33.97it/s]\n",
            "epoch:27 loss:0.20330342650413513: 100%|██████████| 1563/1563 [00:45<00:00, 34.30it/s]\n",
            "epoch:28 loss:0.0060043372213840485: 100%|██████████| 1563/1563 [00:45<00:00, 34.31it/s]\n",
            "epoch:29 loss:0.02909809723496437: 100%|██████████| 1563/1563 [00:45<00:00, 34.45it/s]\n",
            "epoch:30 loss:0.4155571162700653: 100%|██████████| 1563/1563 [00:45<00:00, 34.31it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 성능 평가"
      ],
      "metadata": {
        "id": "CkeaBH2qKs0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"ResNet.pth\", map_location=device))\n",
        "\n",
        "num_corr = 0\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data, label in test_loader:\n",
        "\n",
        "    output = model(data.to(device))\n",
        "    preds = output.data.max(1)[1]\n",
        "    corr = preds.eq(label.to(device).data).sum().item()\n",
        "    num_corr += corr\n",
        "\n",
        "  print(f\"Acurracy:{num_corr/len(test_data)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_SmEDaDKwZi",
        "outputId": "cf207a4e-6fb2-4151-c52d-50c05b1ef811"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurracy:0.8914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "약 0.8914라는 이전 CNN 모델에 비해 향상된 정확도를 확인 가능"
      ],
      "metadata": {
        "id": "zBZvVUwaYfYl"
      }
    }
  ]
}